#### Preamble ####
# Purpose: Cleans the simulated data
# Author: Shivank Goel
# Date: 23rd February 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
# Read the data
url <-
paste0(
"http://data.insideairbnb.com/united-kingdom/england/",
"london/2023-03-14/data/listings.csv.gz"
)
airbnb_data <-
read_csv(
file = url,
guess_max = 20000
)
write_csv(airbnb_data, "airbnb_data.csv")
airbnb_data
#### Preamble ####
# Purpose: Cleans the simulated data
# Author: Shivank Goel
# Date: 23rd February 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
# Read the data
url <-
paste0(
"http://data.insideairbnb.com/france/ile-de-france/paris/2023-12-12/data/listings.csv.gz"
)
airbnb_data <-
read_csv(
file = url,
guess_max = 20000
)
write_csv(airbnb_data, "airbnb_data.csv")
airbnb_data
#### Preamble ####
# Purpose: Cleans the simulated data
# Author: Shivank Goel
# Date: 23rd February 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
# Read the data
url <-
paste0(
"http://data.insideairbnb.com/france/ile-de-france/paris/2023-12-12/data/listings.csv.gz"
)
airbnb_data <-
read_csv(
file = url,
guess_max = 20000
)
write_csv(airbnb_data, "inputs/data/airbnb_data.csv")
airbnb_data
#### Preamble ####
# Purpose: Simulate Airbnb data for Paris with potential data inconsistencies
# Author: Shivank Goel
# Date: 23rd February 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
# Pre-requisites:
# - Need to have installed the 'tidyverse' and 'dplyr' packages.
#### Workspace setup ####
library(tidyverse)
library(dplyr)
#### Simulate Airbnb Data ####
set.seed(123)  # Setting a seed for reproducibility
# Parameters for simulated Airbnb data
n <- 1000  # Number of listings
# Simulating listing IDs
listing_ids <- 1:n
# Simulating host response times (categorical data)
response_times <- sample(c("within an hour", "within a day", "within a few hours", "a few days or more", NA),
n, replace = TRUE, prob = c(0.5, 0.2, 0.2, 0.05, 0.05))
# Simulating prices (numeric data with potential outliers)
set.seed(124)
prices <- rnorm(n, mean = 100, sd = 50)
# Introducing outliers
prices[sample(1:n, 20)] <- prices[sample(1:n, 20)] * 10
# Simulating number of reviews (numeric data)
number_of_reviews <- sample(0:500, n, replace = TRUE)
# Creating a DataFrame for the Airbnb listings
airbnb_data_simulated <- data.frame(
ListingID = listing_ids,
HostResponseTime = response_times,
Price = prices,
NumberOfReviews = number_of_reviews
)
# Introducing human error (duplicated entries for some listings)
duplicate_ids <- sample(listing_ids, 50)
airbnb_data_simulated <- bind_rows(airbnb_data_simulated, airbnb_data_simulated[duplicate_ids, ])
# Shuffling the data to mix duplicates
set.seed(125)
airbnb_data_simulated <- airbnb_data_simulated[sample(1:nrow(airbnb_data_simulated)), ]
write_csv(airbnb_data_simulated, "inputs/data/airbnb_data_simulated.csv")
# Step 2: Handling missing values
# If HostResponseTime is missing, replace with 'unknown'
airbnb_data$HostResponseTime[is.na(airbnb_data$HostResponseTime)] <- 'unknown'
library(readr)
airbnb_data <- read_csv("inputs/data/airbnb_data.csv")
View(airbnb_data)
#### Preamble ####
# Purpose: Cleans the Airbnb Paris data
# Author: Shivank Goel
# Date: 4th March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
# Read the Airbnb Paris data (assuming it's saved as 'airbnb_data.csv')
airbnb_data <- read_csv("inputs/data/airbnb_data.csv")
# Cleaning the data
# Select only the required columns
airbnb_data_selected <- airbnb_data %>%
select(
id,
host_id,
host_response_time,
host_is_superhost,
neighbourhood_cleansed,
property_type,
room_type,
price,
number_of_reviews,
review_scores_rating
)
# Cleaning the data
# Step 1: Handling missing values
# Replace NA in 'host_response_time' with 'unknown'
# Replace NA in 'host_is_superhost' with FALSE
# Replace NA in 'review_scores_rating' with the mean score
airbnb_data_selected <- airbnb_data_selected %>%
mutate(
host_response_time = replace_na(host_response_time, "unknown"),
host_is_superhost = replace_na(host_is_superhost, FALSE),
review_scores_rating = if_else(is.na(review_scores_rating),
mean(review_scores_rating, na.rm = TRUE),
review_scores_rating)
)
# Step 2: Cleaning Price field
# Remove any non-numeric characters and convert to numeric
airbnb_data_selected$price <- as.numeric(gsub("[^0-9.]", "", airbnb_data_selected$price))
# Output the cleaned data
write_csv(airbnb_data_selected, "outputs/data/cleaned_airbnb_data.csv")
library(tidyverse)
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 23rd February 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data <- penguins %>%
# Cleaning or any other required processing steps can be added here
na.omit() # This line can be changed based on specific requirements
# Save the cleaned data (optional)
write_csv(penguins_data, "inputs/data/penguins_data.csv")
# Output the first few rows of the data
head(penguins_data)
# Checking for any illogical values or errors
# Ensuring sex is either male, female, or NA
penguins_data <- penguins_data %>%
mutate(sex = case_when(
sex %in% c("male", "female") ~ sex,
TRUE ~ NA_character_
))
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data <- read_csv("inputs/data/penguins_data.csv")
penguins_data <- penguins() %>%
clean_names() %>%  # Standardizing column names
filter(!is.na(bill_length_mm))  # Removing NA values in bill_length_mm
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data <- penguins() %>%
clean_names() %>%  # Standardizing column names
filter(!is.na(bill_length_mm))
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data =  clean_names(penguins_data) %>%  # Standardizing column names
penguins_data = filter(!is.na(bill_length_mm))
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data =  clean_names(penguins_data) %>%  # Standardizing column names
penguins_data = filter(!is.na(penguins_data$bill_length_mm))
MIT
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data =  clean_names(penguins_data) %>%  # Standardizing column names
# Identifying and handling outliers
# Assuming bill length less than 30mm and greater than 60mm as outliers for this example
penguins_data <- penguins_data %>%
filter(bill_length_mm > 30, bill_length_mm < 60)
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(janitor)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data =  clean_names(penguins_data) %>%  # Standardizing column names
# Identifying and handling outliers
# Assuming bill length less than 30mm and greater than 60mm as outliers for this example
penguins_data <- penguins_data %>%
filter(bill_length_mm > 30, bill_length_mm < 60)
# Purpose: Analyze missing data in penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
library(tidyverse)
library(dplyr)
library(janitor)
library(palmerpenguins)
# Read the penguins data
penguins_data_csv <- read_csv("inputs/data/penguins_data.csv")
# Additionally, load and clean the data again from the palmerpenguins package
penguins_data =  clean_names(penguins_data) # Standardizing column names
# Identifying and handling outliers
# Assuming bill length less than 30mm and greater than 60mm as outliers for this example
penguins_data <- penguins_data %>%
filter(bill_length_mm > 30, bill_length_mm < 60)
# Checking for duplicate rows and removing them
penguins_data <- penguins_data %>%
distinct()
# Checking for any illogical values or errors
# Ensuring sex is either male, female, or NA
penguins_data <- penguins_data %>%
mutate(sex = case_when(
sex %in% c("male", "female") ~ sex,
TRUE ~ NA_character_
))
#### Save data ####
write_csv(penguins_data, "outputs/data/cleaned_penguins_data.csv")
# Displaying the first few rows of the cleaned data
head(penguins_data)
library(tidyverse)
#### Preamble ####
# Purpose: Simulate a scenario for penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
# Pre-requisites:
# - Need to have installed the 'tidyverse' and 'dplyr' packages.
library(tidyverse)
library(dplyr)
library(palmerpenguins)
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Using real penguins data to understand existing relationships
real_penguins_data <- penguins() %>%
filter(species %in% c("Adelie", "Chinstrap", "Gentoo")) %>%
drop_na()
#### Preamble ####
# Purpose: Simulate a scenario for penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
# Pre-requisites:
# - Need to have installed the 'tidyverse' and 'dplyr' packages.
library(tidyverse)
library(dplyr)
library(palmerpenguins)
#### Simulate data ####
cleaned_penguins_data <- read_csv("outputs/data/cleaned_penguins_data.csv")
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Simulating based on cleaned data
# For example, let's simulate bill length and depth with added random noise
simulated_penguins_data <- cleaned_penguins_data %>%
mutate(
simulated_bill_length_mm = bill_length_mm + rnorm(n(), mean = 0, sd = 2),
simulated_bill_depth_mm = bill_depth_mm + rnorm(n(), mean = 0, sd = 1)
)
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Simulating based on cleaned data
# For example, let's simulate bill length and depth with added random noise
simulated_penguins_data <- cleaned_penguins_data %>%
mutate(
simulated_bill_length_mm = bill_length_mm + rnorm(n(), mean = 0, sd = 2),
simulated_bill_depth_mm = bill_depth_mm + rnorm(n(), mean = 0, sd = 1)
)
# Summary statistics for bill length for each species
summary_stats <- real_penguins_data %>%
group_by(species) %>%
summarise(
mean_bill_length = mean(bill_length_mm, na.rm = TRUE),
sd_bill_length = sd(bill_length_mm, na.rm = TRUE)
)
#### Preamble ####
# Purpose: Simulate a scenario for penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
# Pre-requisites:
# - Need to have installed the 'tidyverse' and 'dplyr' packages.
library(tidyverse)
library(dplyr)
library(palmerpenguins)
#### Simulate data ####
cleaned_penguins_data <- read_csv("outputs/data/cleaned_penguins_data.csv")
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Simulating based on cleaned data
# For example, let's simulate bill length and depth with added random noise
simulated_penguins_data <- cleaned_penguins_data %>%
mutate(
simulated_bill_length_mm = bill_length_mm + rnorm(n(), mean = 0, sd = 2),
simulated_bill_depth_mm = bill_depth_mm + rnorm(n(), mean = 0, sd = 1)
)
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Simulating based on cleaned data
# For example, let's simulate bill length and depth with added random noise
simulated_penguins_data <- cleaned_penguins_data %>%
mutate(
simulated_bill_length_mm = bill_length_mm + rnorm(n(), mean = 0, sd = 2),
simulated_bill_depth_mm = bill_depth_mm + rnorm(n(), mean = 0, sd = 1)
)
# Summary statistics for bill length for each species
summary_stats <- cleaned_penguins_data %>%
group_by(species) %>%
summarise(
mean_bill_length = mean(bill_length_mm, na.rm = TRUE),
sd_bill_length = sd(bill_length_mm, na.rm = TRUE)
)
# Simulating bill lengths for each species based on the summary statistics
simulate_bill_length <- function(species_name, n) {
species_stats <- filter(summary_stats, species == species_name)
rnorm(n, mean = species_stats$mean_bill_length, sd = species_stats$sd_bill_length)
}
# Number of simulations for each species
n_simulations <- 100
# Generating simulated data
simulated_penguins_data <- tibble(
species = rep(c("Adelie", "Chinstrap", "Gentoo"), each = n_simulations),
bill_length_mm = c(
simulate_bill_length("Adelie", n_simulations),
simulate_bill_length("Chinstrap", n_simulations),
simulate_bill_length("Gentoo", n_simulations)
)
)
write_csv(simulated_penguins_data, "outputs/data/simulated_penguins_data.csv")
#### Preamble ####
# Purpose: Simulate a scenario for penguins dataset
# Author: Shivank Goel
# Date: 3rd March 2024
# Contact: shivankg.goel@mail.utoronto.ca
# License: MIT
# Pre-requisites:
# - Need to have installed the 'tidyverse' and 'dplyr' packages.
library(tidyverse)
library(dplyr)
library(palmerpenguins)
#### Simulate data ####
cleaned_penguins_data <- read_csv("outputs/data/cleaned_penguins_data.csv")
#### Simulate data ####
set.seed(123)  # Setting a seed for reproducibility
# Simulating based on cleaned data
# For example, let's simulate bill length and depth with added random noise
simulated_penguins_data <- cleaned_penguins_data %>%
mutate(
simulated_bill_length_mm = bill_length_mm + rnorm(n(), mean = 0, sd = 2),
simulated_bill_depth_mm = bill_depth_mm + rnorm(n(), mean = 0, sd = 1)
)
# Simulate missing data in bill_length_mm variable
# For example, let's randomly set 10% of bill_length_mm data to NA (missing)
missing_indices <- sample(1:nrow(cleaned_penguins_data), 0.1 * nrow(cleaned_penguins_data))
cleaned_penguins_data$bill_length_mm[missing_indices] <- NA
# Summary statistics for bill length for each species
summary_stats <- cleaned_penguins_data %>%
group_by(species) %>%
summarise(
mean_bill_length = mean(bill_length_mm, na.rm = TRUE),
sd_bill_length = sd(bill_length_mm, na.rm = TRUE)
)
# Simulating bill lengths for each species based on the summary statistics
simulate_bill_length <- function(species_name, n) {
species_stats <- filter(summary_stats, species == species_name)
rnorm(n, mean = species_stats$mean_bill_length, sd = species_stats$sd_bill_length)
}
# Number of simulations for each species
n_simulations <- 100
# Generating simulated data
simulated_penguins_data <- tibble(
species = rep(c("Adelie", "Chinstrap", "Gentoo"), each = n_simulations),
bill_length_mm = c(
simulate_bill_length("Adelie", n_simulations),
simulate_bill_length("Chinstrap", n_simulations),
simulate_bill_length("Gentoo", n_simulations)
)
)
write_csv(simulated_penguins_data, "outputs/data/simulated_penguins_data.csv")
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(here)
library(kableExtra)
cleaned_data <- read_csv(here::here("outputs/data/cleaned_penguins_data.csv"))
#| label: tbl-cleaned-data
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: "Sample of Cleaned Data"
head(cleaned_data, 6) %>%
kable(
booktabs = TRUE,
longtable = FALSE
) %>%
kable_styling(latex_options = c("striped", "scale_down"), font_size = 6)
#| label: fig-marks
#| fig-cap: "Original Distribution of Bill Length in Penguins"
#| echo: false
library(ggplot2)
library(dplyr)
# Plotting the original bill_length_mm distribution
ggplot(cleaned_penguins_data, aes(x = bill_length_mm)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black") +
theme_minimal()
